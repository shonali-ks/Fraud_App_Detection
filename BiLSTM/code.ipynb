{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "enQhZttdn9e8"
      },
      "source": [
        "\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,Bidirectional,TimeDistributed\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX8YI0U5wxSg",
        "outputId": "7c3d5153-8fdc-41d0-d82c-ff207097677a"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68iTC9OXoqLz"
      },
      "source": [
        "data = pd.read_csv('dataset.csv')\n",
        "data= data.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbqcfUFwoeSt"
      },
      "source": [
        "def preprocess(text):  \n",
        "    text = text.translate(string.punctuation)\n",
        "    text = text.lower().split()\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
        "    text = \" \".join(text)\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = text.split()\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    stemmed_words = [stemmer.stem(word) for word in text]\n",
        "    text = \" \".join(stemmed_words)\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l4FEHVKof9g"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: x.lower()) #lower caseing\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x))) # removing special chars\n",
        "data['text'] = data.text.str.replace('rt','') # removing \"rt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wagr4VsrN0Dr",
        "outputId": "58f6f9d9-7cc3-43b6-ba5d-61ad4d5129a7"
      },
      "source": [
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "X = pad_sequences(X)\n",
        "# print(X[:2])\n",
        "\n",
        "Y = pd.get_dummies(data['class']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11972, 504) (11972, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HItF-tH7OMuv",
        "outputId": "7e141833-e7de-46fc-af93-e42e80995f54"
      },
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 504, 128)          256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 504, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 394       \n",
            "=================================================================\n",
            "Total params: 511,194\n",
            "Trainable params: 511,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfvPO9NCOYoX",
        "outputId": "30d403bd-86e7-4631-b017-50dd6ea46973"
      },
      "source": [
        "batch_size = 128\n",
        "model.fit(X_train, Y_train, epochs = 3, batch_size=batch_size, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "94/94 [==============================] - 617s 7s/step - loss: 0.6279 - accuracy: 0.6596\n",
            "Epoch 2/3\n",
            "94/94 [==============================] - 611s 6s/step - loss: 0.2663 - accuracy: 0.9047\n",
            "Epoch 3/3\n",
            "94/94 [==============================] - 611s 7s/step - loss: 0.1743 - accuracy: 0.9411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc9673cb390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_xoZ0LzQX2O",
        "outputId": "3adac78d-d834-42d7-d320-94f72b590e17"
      },
      "source": [
        "data_majority = data[data['class'] == 0]\n",
        "data_minority = data[data['class'] == 1]\n",
        "\n",
        "bias = data_minority.shape[0]/data_majority.shape[0]\n",
        "\n",
        "train = pd.concat([data_majority.sample(frac=0.8,random_state=200),\n",
        "         data_minority.sample(frac=0.8,random_state=200)])\n",
        "test = pd.concat([data_majority.drop(data_majority.sample(frac=0.8,random_state=200).index),\n",
        "        data_minority.drop(data_minority.sample(frac=0.8,random_state=200).index)])\n",
        "\n",
        "train = shuffle(train)\n",
        "test = shuffle(test)\n",
        "\n",
        "print('positive data in training:',(train['class'] == 1).sum())\n",
        "print('negative data in training:',(train['class'] == 0).sum())\n",
        "print('positive data in test:',(test['class'] == 1).sum())\n",
        "print('negative data in test:',(test['class'] == 0).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive data in training: 5635\n",
            "negative data in training: 6337\n",
            "positive data in test: 1409\n",
            "negative data in test: 1584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGtFSWVrvvlV"
      },
      "source": [
        "Upsampling data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eZFosRHQznY",
        "outputId": "5f20f52c-85cd-4bbe-ec31-e7a9df01a2c2"
      },
      "source": [
        "data_majority = train[train['class'] == 0]\n",
        "data_minority = train[train['class'] == 1]\n",
        "\n",
        "print(\"majority class before upsample:\",data_majority.shape)\n",
        "print(\"minority class before upsample:\",data_minority.shape)\n",
        "\n",
        "# Upsample minority class\n",
        "data_minority_upsampled = resample(data_minority, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples= data_majority.shape[0],    # to match majority class\n",
        "                                 random_state=123) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
        " \n",
        "# Display new class counts\n",
        "print(\"After upsampling\\n\",data_upsampled['class'].value_counts(),sep = \"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "majority class before upsample: (6337, 2)\n",
            "minority class before upsample: (5635, 2)\n",
            "After upsampling\n",
            "1.0    6337\n",
            "0.0    6337\n",
            "Name: class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMpEacMwuQAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89f769e-294a-46b4-e0a3-32c718b0f966"
      },
      "source": [
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values) # training with whole data\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(data_upsampled['text'].values)\n",
        "X_train = pad_sequences(X_train,maxlen=29)\n",
        "Y_train = pd.get_dummies(data_upsampled['class']).values\n",
        "print('x_train shape:',X_train.shape)\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(test['text'].values)\n",
        "X_test = pad_sequences(X_test,maxlen=29)\n",
        "Y_test = pd.get_dummies(test['class']).values\n",
        "print(\"x_test shape\", X_test.shape)\n",
        "embed_dim = 128\n",
        "lstm_out = 192"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (12674, 29)\n",
            "x_test shape (2993, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_vd202d-HYX"
      },
      "source": [
        "LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg9Lf8PaRBA2",
        "outputId": "3872b246-5962-419d-8f29-ef4fc22c2ac6"
      },
      "source": [
        "\n",
        "# model\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(max_fatures, embed_dim,input_length = X_train.shape[1]))\n",
        "model1.add(SpatialDropout1D(0.4))\n",
        "model1.add(LSTM(lstm_out, dropout=0.4, recurrent_dropout=0.4))\n",
        "model1.add(Dense(2,activation='softmax'))\n",
        "model1.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model1.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 29, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 29, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 192)               246528    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 386       \n",
            "=================================================================\n",
            "Total params: 502,914\n",
            "Trainable params: 502,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWfpMXMaRH1_",
        "outputId": "fe102dc3-81e5-496e-d228-324d5587788a"
      },
      "source": [
        "batch_size = 128\n",
        "# also adding weights\n",
        "class_weights = {0: 1 ,\n",
        "                1: 1.6/bias }\n",
        "model1.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, verbose = 1,\n",
        "          class_weight=class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 37s 336ms/step - loss: 0.8014 - accuracy: 0.5984\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 34s 337ms/step - loss: 0.3541 - accuracy: 0.8971\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 34s 336ms/step - loss: 0.2504 - accuracy: 0.9271\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 33s 335ms/step - loss: 0.2498 - accuracy: 0.9348\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.2464 - accuracy: 0.9233\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 34s 335ms/step - loss: 0.1846 - accuracy: 0.9509\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.1596 - accuracy: 0.9573\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 33s 335ms/step - loss: 0.1570 - accuracy: 0.9588\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.1385 - accuracy: 0.9647\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 34s 336ms/step - loss: 0.1272 - accuracy: 0.9669\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 34s 336ms/step - loss: 0.1096 - accuracy: 0.9735\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 34s 338ms/step - loss: 0.1361 - accuracy: 0.9634\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 34s 336ms/step - loss: 0.1079 - accuracy: 0.9707\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 34s 337ms/step - loss: 0.1191 - accuracy: 0.9702\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 34s 339ms/step - loss: 0.0968 - accuracy: 0.9755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc96f1a01d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTDopH0gRUpb",
        "outputId": "33b0f3db-7ff9-4899-98e8-4abb51eb37a8"
      },
      "source": [
        "Y_pred = model1.predict_classes(X_test,batch_size = batch_size)\n",
        "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
        "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
        "print(classification_report(df_test.true, df_test.pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90      1584\n",
            "           1       0.90      0.87      0.88      1409\n",
            "\n",
            "    accuracy                           0.89      2993\n",
            "   macro avg       0.89      0.89      0.89      2993\n",
            "weighted avg       0.89      0.89      0.89      2993\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmQKXJ2p-KJw"
      },
      "source": [
        "BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbYseeue9-7r",
        "outputId": "30ef6625-d2a3-40b4-8499-576a6f66e960"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Embedding(max_fatures, embed_dim,input_length = X_train.shape[1]))\n",
        "model2.add(SpatialDropout1D(0.4))\n",
        "model2.add(Bidirectional(LSTM(100, dropout=0.4, recurrent_dropout=0.4)))\n",
        "model2.add(Dense(2,activation='softmax'))\n",
        "model2.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model2.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 29, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 29, 128)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               183200    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 439,602\n",
            "Trainable params: 439,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N51NZqzc-Z2y",
        "outputId": "87ee72c3-b8df-4749-97d0-f4136603267c"
      },
      "source": [
        "batch_size = 128\n",
        "class_weights = {0: 1 ,\n",
        "                1: 1.6/bias }\n",
        "model2.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, verbose = 1,\n",
        "          class_weight=class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 34s 284ms/step - loss: 0.8437 - accuracy: 0.5514\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.3530 - accuracy: 0.8942\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.2703 - accuracy: 0.9237\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.2096 - accuracy: 0.9477\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.1809 - accuracy: 0.9560\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.1728 - accuracy: 0.9559\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.1554 - accuracy: 0.9635\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.1352 - accuracy: 0.9643\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.1201 - accuracy: 0.9684\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.1060 - accuracy: 0.9759\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.1119 - accuracy: 0.9724\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0956 - accuracy: 0.9793\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.1015 - accuracy: 0.9766\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0842 - accuracy: 0.9787\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0813 - accuracy: 0.9830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc96db2e1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynVNCSJd_IT_",
        "outputId": "d3b615fa-c777-49e8-8034-43f996a6d4b5"
      },
      "source": [
        "Y_pred = model2.predict_classes(X_test,batch_size = batch_size)\n",
        "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
        "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
        "print(classification_report(df_test.true, df_test.pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90      1584\n",
            "           1       0.90      0.88      0.89      1409\n",
            "\n",
            "    accuracy                           0.89      2993\n",
            "   macro avg       0.89      0.89      0.89      2993\n",
            "weighted avg       0.89      0.89      0.89      2993\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MjZQ39FEFLP",
        "outputId": "8d55d324-f8ef-4d33-f717-84107bf95a2b"
      },
      "source": [
        "model2.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 2s 19ms/step - loss: 0.4315 - accuracy: 0.8938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4314849376678467, 0.8937520980834961]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L8Z1YZSyqdm"
      },
      "source": [
        "Save model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W2FXe98yp7C"
      },
      "source": [
        "model2.save('bilstm_final.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW1hit1D6MbE",
        "outputId": "13d13cdb-6bf4-4dc8-ec07-4e2ff8216bc8"
      },
      "source": [
        "new_model = tf.keras.models.load_model('bilstm_final.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 29, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_3 (Spatial (None, 29, 128)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 200)               183200    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 439,602\n",
            "Trainable params: 439,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xnjj7Ij_F8N",
        "outputId": "5cf0aac4-46a7-4f39-b0ad-ecb4f16ab928"
      },
      "source": [
        "loss, acc = new_model.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 3s 20ms/step - loss: 0.4315 - accuracy: 0.8938\n",
            "Restored model, accuracy: 89.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4zkmygLJeSt"
      },
      "source": [
        "Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptLiJT2n_Zrq",
        "outputId": "958d5f17-424e-4c1c-9b2e-3f5f932c14ef"
      },
      "source": [
        "!pip install google_play_scraper"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google_play_scraper\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/4c/55f501b3e41b4508f622f79ca2ea385b84bfe88f5e4b9a626cbdcab87496/google-play-scraper-0.2.1.tar.gz (49kB)\n",
            "\r\u001b[K     |██████▋                         | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 20kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 30kB 23.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 40kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: google-play-scraper\n",
            "  Building wheel for google-play-scraper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-play-scraper: filename=google_play_scraper-0.2.1-cp37-none-any.whl size=22199 sha256=141cd226dc069aa5fb2b81e54164c943912189dd6b0ccee217b62dd34f1d0148\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/fe/59/aaed9c7885041da68908f5e45f2796bf77696ac83874afd02c\n",
            "Successfully built google-play-scraper\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6_8afuw_dFs"
      },
      "source": [
        "from google_play_scraper import app\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzS_ZY_o_eab"
      },
      "source": [
        "link=\"https://play.google.com/store/apps/details?id=com.meesho.supply\"\n",
        "findId=link.find('id=')\n",
        "\n",
        "url=link[findId+3:]\n",
        "file = open(\"cc.txt\", \"w\",encoding='utf-8')\n",
        "file.write(str(app(\n",
        "    url,\n",
        "    lang='en', # defaults to 'en'\n",
        "    country='us' # defaults to 'us'\n",
        ")))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjmea1L1AZ9w"
      },
      "source": [
        "myfile=[]\n",
        "with open(\"cc.txt\",encoding='utf8') as mydata:\n",
        "\tfor data in mydata:\n",
        "\t\tmyfile.append(data)\n",
        "start=myfile[0].find('comments')\n",
        "end=myfile[0].find('editorsChoice')\n",
        "c=data[start:end]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uw96SgvCp0y"
      },
      "source": [
        "def preprocess(text):  \n",
        "    text = text.translate(string.punctuation)\n",
        "    text = text.lower().split()\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
        "    text = \" \".join(text)\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = text.split()\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    stemmed_words = [stemmer.stem(word) for word in text]\n",
        "    text = \" \".join(stemmed_words)\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z3ql5LL6r0s"
      },
      "source": [
        "c= c.lower() \n",
        "c =  re.sub('[^a-zA-z0-9\\s]','',c) \n",
        "c= c.replace('rt','') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8PJG8QhCiQ6",
        "outputId": "053a2d67-ad07-4c4d-d45a-acfd28aecb2c"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "c = preprocess(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13B8khqx_kEp",
        "outputId": "3850f26b-55f4-4290-99b0-d77b74b4725e"
      },
      "source": [
        "tokenizer = Tokenizer(num_words= 200)\n",
        "tokenizer.fit_on_texts(c)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(c)\n",
        "data = pad_sequences(sequences, maxlen=200)\n",
        "result=np.argmax(new_model.predict(data), axis=-1)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 29) for input KerasTensor(type_spec=TensorSpec(shape=(None, 29), dtype=tf.float32, name='embedding_3_input'), name='embedding_3_input', description=\"created by layer 'embedding_3_input'\"), but it was called on an input with incompatible shape (None, 200).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuIcv_rVaiC-",
        "outputId": "7f60c491-b53c-4039-e8bc-fdd924f8e0b2"
      },
      "source": [
        "result.sum()/len(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00995732574679943"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}